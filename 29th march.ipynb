{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f80cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Lasso Regression and Its Difference from Other Techniques:\n",
    "\n",
    "# Lasso Regression, or Least Absolute Shrinkage and Selection Operator, is a \n",
    "# regularization technique used in linear regression to prevent overfitting by \n",
    "# adding a penalty term to the least squares loss function.\n",
    "# Unlike other regression techniques, Lasso Regression adds an L1 penalty term \n",
    "# to the cost function, which leads to sparsity in the coefficient estimates by\n",
    "# setting some coefficients exactly to zero, effectively performing feature \n",
    "# selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be660e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Advantage of Lasso Regression in Feature Selection:\n",
    "\n",
    "# The main advantage of using Lasso Regression in feature selection is its\n",
    "# ability to automatically select the most relevant features by setting the \n",
    "# coefficients of irrelevant features to zero.\n",
    "# This helps in reducing the dimensionality of the dataset and improving model\n",
    "# interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417a7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Interpretation of Coefficients in Lasso Regression:\n",
    "\n",
    "# The coefficients in Lasso Regression represent the relationship between each \n",
    "# predictor variable and the response variable, considering the presence of all\n",
    "# other predictors in the model.\n",
    "# Coefficients with non-zero values indicate the importance of the corresponding\n",
    "# predictors in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf98727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Tuning Parameters and Their Effects in Lasso Regression:\n",
    "\n",
    "# The main tuning parameter in Lasso Regression is the regularization parameter, \n",
    "# lambda (位).\n",
    "# 位 controls the strength of the penalty term and thus the degree of \n",
    "# regularization applied to the coefficients.\n",
    "# Higher values of 位 lead to more aggressive shrinkage of coefficients and \n",
    "# sparser models, while lower values of 位 result in less shrinkage and \n",
    "# potentially more predictors being retained in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aee39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Multiple Linear Regression Model:\n",
    "\n",
    "# Multiple linear regression is an extension of simple linear regression \n",
    "# where there are multiple independent variables predicting the dependent \n",
    "# variable.\n",
    "\n",
    "# It differs from simple linear regression in that it can capture more complex \n",
    "# relationships between the predictors and the response variable by considering\n",
    "# multiple factors simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96426242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Difference Between Ridge Regression and Lasso Regression:\n",
    "\n",
    "# Ridge Regression adds an L2 penalty term to the cost function, while Lasso \n",
    "# Regression adds an L1 penalty term.\n",
    "# Ridge Regression shrinks coefficients towards zero but does not set them \n",
    "# exactly to zero, while Lasso Regression can set coefficients exactly to zero,\n",
    "# effectively performing feature selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d25b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Handling Multicollinearity in Lasso Regression:\n",
    "\n",
    "# Lasso Regression can handle multicollinearity in the input features by \n",
    "# shrinking the coefficients of correlated predictors towards zero.\n",
    "# In cases of high multicollinearity, Lasso Regression may set one of the \n",
    "# correlated coefficients to zero while retaining the other, effectively \n",
    "# choosing one predictor over the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e94c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
